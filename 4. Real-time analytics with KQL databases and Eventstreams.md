# Real-time analytics with KQL databases and Eventstreams

## Add a new KQL database and ingest data

Navigate to the "Fabric Workshop xxx" workspace and click the "New" from the ribbon. If you are using the Real-Time Analytics persona, select "KQL Database", otherwise select "More options" and select the "KQL Database" tile.

Name the database "MyKusto".

Once it is created, add some sample data. Click on the "Sample Data" tile. and select "Automotive operations analytics". This is a truncated database of New York taxi operations over a two year period, and the largest provided sample data set. This will take a few moments to load.

![](assets/20240320_071828_image.png)

Expand the "Automotive" table to view the schema.

Click the "Explore your data" button in the upper right hand corner. A window will open with some sample queries.

Replace "YOUR_TABLE_HERE" with "Automotive" for the first two queries.

![](assets/20240320_072256_image.png)

Highlight rows 8 and 9, and click the "Run" button. You will see a random selection of 100 records from the table.

![](assets/20240320_072439_image.png)

Highlight rows 12 and 13 and click the "Run" button. You should see that there are over 2 million records in the table.

![](assets/20240320_072708_image.png)

## Create a Query Set for multiple sharable queries

The data explorer is handy, but if you're working extensively with KQL, you will likely want to use a purpose built client like Azure Data Studio or Visual Studio Code or the Azure Data Explorer client. Within Fabric, the KQL Queryset is a sharable version of the Azure Data Explorer client.

Close the "Explore your data" window, and navigate back to the workspace. Click the "New" button in the ribbon, select "More options" and select the KQL Queryset tile. Name it "Taxi Queries" and click "Create".

![](assets/20240320_073318_image.png)

Select the"MyKusto" database created above, and click "Connect".

Delete the queries automatically added to the default tab. Note that you can add tabs to wrk with different queries efficiently, and when saved, others can work with this query set.

Add the following query that retrieves a number of metric by day and borough:

```PlainText
Automotive
| summarize Fares = sum(fare_amount), Passengers = sum(passenger_count), distance = sum(trip_distance) by Day = bin(pickup_datetime,1d), pickup_boroname
```

The query summarizes fares, passengers, and distances by borough name. Click on the "Run" button to run the query, and note the time required to run in the results window. It should be a around 1 second.

![](assets/20240320_074000_image.png)

## Build a materialized view

While running a summarized query against 3 million rows of data is good, more complex queries with elements like joins, etc, and larger amounts of data can present a performance challenge. If these query patterns are common, it is a good idea to build a materialized view.

While still in the queryset, add a new tab and add in the following code:

```PlainText
.create async materialized-view with(backfill = true) FareSummary on table Automotive { 
Automotive
| summarize Fares = sum(fare_amount), Passengers = sum(passenger_count), distance = sum(trip_distance) by Day = bin(pickup_datetime,1d), pickup_boroname
}
```

The "async" directive tells Fabric to process this command in the background, which is necessary to use the "backfill=true" option. Backfill tells Fabric to include all current data in the materialized view - without it, the view. will only contain new data after it is run. Click on the "Run" button in the ribbon. The result will be an OperationId. This Id can be used to query the status of the operation.

Wait a few seconds and then refresh the database in the left pane by selecting the database in the dropdown, and clicking the refresh icon.

![](assets/20240320_074511_image.png)

You will see a new node appear named "Materialized Views". Open the node and open the "FareSummary" Materialized view to see the schema.

![](assets/20240320_074608_image.png)

Open a new tab, and simply enter the name of the view by double clicking on it in the explorer view.. Click on the "Run" button. The first ruin is initialization, so run it a second time. It should run in less than half the time that the original query ran. Also note the number of rows returned.

![](assets/20240320_074847_image.png)

## Build a Power BI report

From the queryset, click on the "Build Power BI report" button.

Close the filter pane, and add bar chart to the canvas.

Add "pickup_boroname" to the Y-axis, and "Fares" to the X-axis.

Select File-Save and name the report NYCCabs. "My workspace" is selected by default. **Select the "Fabric Workshop xxx" workspace** and click "Continue".

![](assets/20240320_091812_image.png)

Navigate back to the "Fabric Workshop xxx" workspace. Note that there is both a report and a semantic model created. KQL data is not stored natively in OneLake (more on that below), so the semantic model is a Direct Query (not Direct Lake) connection to the KQL data.

We need to allow model editing in a browser. Click on "Workspace settings" from the ribbon (this may be under an ellipsis). Open the "Power BI" blade and select "General". check the bottom checkbox to allow model editing.

![](assets/20240320_092219_image.png)

Close the settings window and navigate back to the workspace. Click on the "NYCCabs" semantic model.

Click the "Open data model" button in the ribbon.

From the ribbon, click the "New measure" button.

Enter the following in the editor:

```PlainText
Trips = COUNTROWS('Kusto Query Result')
```

![](assets/20240320_092438_image.png)

Navigate back to the workspace, and click on the NYCCabs report.

Click "Edit" in the ribbon. Add a new card visual to the report, and add the new "Trips" measure to its Fields.

![](assets/20240320_092701_image.png)

Save the report and navigate back to the workspace.

## Materialize KQL data in the lakehouse

As mentioned above, KQL does not store its data in OneLake natively. However, it can be mirrored into OneLake in a read only manner for integration with other systems.

Open the "MyKusto" KQL database. Click the pencil icon beside "OneLake availability".

Set the value to "Active" and click "Done".

![](assets/20240320_093056_image.png)

If the value still shows as inactive, refresh the screen.

Select the "Automotive" database. If "OneLake availability shows as "Inactive", activate it.

Navigate back to the workspace, and open the "Lakehouse_Fabxxx" lakehouse.

From the ribbon, click on "Get data", and select "New shortcut".

Select the OneLake tile, and then select the "MyKusto" KQL database. Click "Next".

![](assets/20240320_093404_image.png)

Expand the "Tables" node, and check the box next to the "Automotive" table. Click "Next".

Click the "Create" button, and then "Close". You will eventually see the KQL data displayed as a delta table in the lakehouse.

From the lakehouse, select "Automotive". Click on the ellipsis to the right of "Automotive" and select "View files". These are the delta-parquet files behind the lakehouse table. (If the files have not yet been loaded, use the "thermostat_readings" table instead to see its backing files).

![](assets/20240320_094045_image.png)

## Create an event stream and output to KQL and Lakehouse

Navigate to the "Fabric Workshop xxx" workspace and click the "New" from the ribbon. If you are using the Real-Time Analytics persona, select "Eventstream", otherwise select "More options" and select the "Eventstream" tile.

Name your Eventstream "BikesFeed". Click the "Create" button.

![](assets/20240320_094721_image.png)

Click on "New source" and select "Sample data". (This is a selection sample data feeds provided by Microsoft for testing).

Name the source "Rental_Bikes" and select "Bicycles (Reflex compatible)" from the dropdown menu. Click the "Add" button.

Click on the "BikesFeed" tile in the middle and observe the Data preview. It may take a few moments to load.

![](assets/20240320_095013_image.png)

Click the "Data insights" tab to ensure that data is flowing.

Click on "New destination" and select "KQL Database".

Select "Event processing before ingestion", and the following options. When done, click "Add and configure".

* Destination name: BikesSummary
* Workspace: Fabric Workshop xxx
* KQL Database: MyKusto
* Input data format: Json

Select the "Create New" link under "Destination table". Name the new table "BikesSummary".

![](assets/20240320_095250_image.png)

Click the "Open event processor" button at the bottom.

Select the line between the two boxes and delete it.

From the ribbon, press the "Operations" button, and select "Group by".

Connect the "BikesFeed" source to the Group by action, and that action to the "KQL Database 1" destination.

![](assets/20240320_095544_image.png)

Click on the "Groupby1" action. Select the Average aggregation for the "No_Bikes" field, and click the "Add" button. Click on "+ Add aggregate function" and create another Average for the No_Empty_Docks" field.

Scroll down to the Settings section and select the "Neighbourhood" field to group the aggregations. Leave the time window as "Tumbling", and set the duration to 1 minute. Click the "Done" button in the "Group by" pane, and then "Done" in the editor window.

![](assets/20240320_100417_image.png)

Finally, click the "Add" at the bottom. The destination table will be created, and data will begin flowing to it. Click on the "BikesSummary" node to see a preview of the streaming grouped data.

Click the "+" button to the right of the "BikesFeed" node. Select "Lakehouse" and fill in the following values:

* Destination name: BikesLive
* Workspace: Fabric Workshop xxx
* Lakehouse: Lakehouse_Fabxxx
* Input data format: Json

Select the "Create New" link under "Delta table". Name the new table "BikesLive".

![](assets/20240320_101510_image.png)

We will not process these events, so click on the "Add" button. The Delta table will be created, and data will begin flowing.

![](assets/20240320_102239_image.png)

## Build a Power BI report from the lakehouse

Navigate back to the "Fabric Workshop xxx" workspace, and open the "Lakehouse_Fabxxx" lakehouse. Click the "BikesLive" table to see a preview of the data.

![](assets/20240320_102544_image.png)

Change from "Lakehouse" to "SQL analytics endpoint" with the button in the upper right of the ribbon. Select the "BikesLive" table again. Hover over the "BikesLive" node, click the ellipsis, and select "Add to default dataset". If you receive an error, repeat the process.

Click the "New measure" button in the ribbon. Add the following measure:

```PlainText
Latest (UTC) = MAX(BikesLive[EventProcessedUtcTime])
```

Select the "Model" tab at the bottom of the Explorer pane. Find the "BikesLive" table and select the "Latest (UTC)" measure.

Change the value for "Format" to "Custom" and add the following Custom format in the box below:

```PlainText
yyyy-MM-dd yyyy-MM-dd hh:mm:ss
```

![](assets/20240320_103303_image.png)

Click the "New report" button on the ribbon.

Open the "BikesLive" table in the "Data" pane on the right.

Add a new Card visual to the report canvas, and add the "Latest (UTC) measure to it.

Add a table to the canvas, and add the following fields: EventProcessedUTCTime, Neighbourhood, No_Bikes, No_Empty_Docks

Change the Aggregation for No_Bikes and No_Empty_Docks to Average by using the dropdowns in the Visualizations pane.

![](assets/20240320_103900_image.png)

Refresh the report from the upper right corner of the ribbon. Note that the latest readings have (likely)changed.

Save the report, and name it "Bikes report in real time". Note that any time it is opened, it will display up to date data with no refresh.
